{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.ticker as ticker\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import json\n",
    "import json_stream\n",
    "from tqdm import tqdm\n",
    "import scipy.linalg as linalg\n",
    "import scipy.optimize as opt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define linear function for fitting\n",
    "def lin_fit_fun(x,m,b):\n",
    "    return m*x+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath of json file containing training data. File should contain the fields: \n",
    "# \"learning_rate\",\n",
    "# \"gamma\" (learning rate decay factor),\n",
    "# \"margin\",\n",
    "# \"momentum\",\n",
    "# \"batch_size\",\n",
    "# \"epochs\",\n",
    "# \"input_size\",\n",
    "# \"output_size\",\n",
    "# \"depth\",\n",
    "# \"width\",\n",
    "# \"test_accuracy\",\n",
    "# \"losses\",\n",
    "# \"err_rates\" (validation),\n",
    "# \"step\" (number of epochs between weight measurement),\n",
    "# \"parameters\" (a list of lists containing the weights at each measurement)\n",
    "\n",
    "filepath=\"train_data/mnist_paper_relu_lr-4.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(filepath,\"r\")\n",
    "in_data=json_stream.load(file,persistent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data[\"learning_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data[\"gamma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data[\"momentum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-in_data[\"test_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=in_data[\"losses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_rates=in_data[\"err_rates\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step=in_data[\"step\"]\n",
    "print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=in_data[\"epochs\"]\n",
    "print(epochs)\n",
    "ep_arr=np.arange(0,epochs+1,step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers=in_data[\"depth\"]+1\n",
    "print(num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=in_data[\"parameters\"]\n",
    "#convert to arrays\n",
    "params=[[np.array(item) for item in t_param] for t_param in params]\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers=[W.shape[1] for W in params[0]]+[params[0][num_layers-2].shape[0]]\n",
    "N=sum(layers)\n",
    "print(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new epoch array and change the first element from 0 to 0.7 for plotting purposes\n",
    "m_ep_arr=np.array(ep_arr,dtype=float)\n",
    "m_ep_arr[0]=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit log-log loss data to line, modify starting index as needed\n",
    "lin_popt,_=opt.curve_fit(lin_fit_fun,np.log(ep_arr[10:]),np.log(losses[10:]))\n",
    "print(lin_popt)\n",
    "\n",
    "# plot losses\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(ep_arr,losses,linewidth=5,alpha=0.8,label='Data')\n",
    "# plt.plot(ep_arr[1:],np.exp(lin_fit_fun(np.log(ep_arr[1:]),*lin_popt)),'k--',label='Power-law fit')\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.ylabel('Loss',fontsize=20)\n",
    "plt.ylim((None,max(losses)+5))\n",
    "# plt.savefig('paper_plots/loss_lr-4_2.pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# plot losses on log-symlog plot\n",
    "plt.figure(figsize=(8,6))\n",
    "ax=plt.gca()\n",
    "plt.plot(m_ep_arr[:],losses[:],linewidth=5,alpha=0.8,label='Data')\n",
    "# plt.plot(ep_arr[1:],np.exp(lin_fit_fun(np.log(ep_arr[1:]),*lin_popt)),'k',linestyle='dashed',label='Power-law fit')\n",
    "plt.yscale('log')\n",
    "ax.set_xscale('symlog',linthresh=1)\n",
    "plt.xticks(list(plt.xticks()[0]) + [m_ep_arr[0]],list(plt.xticks()[1])+['$0$'])\n",
    "ll=ticker.SymmetricalLogLocator(linthresh=1,base=10)\n",
    "ll.set_params([2,3,4,5,6,7,8,9])\n",
    "ax.xaxis.set_minor_locator(ll)\n",
    "plt.xlim([m_ep_arr[0]-0.1,600])\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.ylabel('Loss',fontsize=20)\n",
    "# plt.savefig('paper_plots/loss_lr-4_2_log.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit log-log validation error rate data in different regimes\n",
    "# lin_popt,_=opt.curve_fit(lin_fit_fun,np.log(ep_arr[2:40]),np.log(err_rates[2:40]))\n",
    "# print(lin_popt)\n",
    "\n",
    "# lin_popt_2,_=opt.curve_fit(lin_fit_fun,np.log(ep_arr[60:]),np.log(err_rates[60:]))\n",
    "# print(lin_popt_2)\n",
    "\n",
    "# plot validation error rate\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(ep_arr,err_rates,linewidth=5,alpha=0.8,label='Data')\n",
    "plt.plot(ep_arr,np.exp(lin_fit_fun(np.log(ep_arr),*lin_popt)),'k',linestyle='dashed',label='Power-law fit')\n",
    "# plt.plot(ep_arr,np.exp(lin_fit_fun(np.log(ep_arr),*lin_popt_2)),'r',linestyle='dashed',label='Late Power-law fit')\n",
    "plt.legend(fontsize=15)\n",
    "plt.ylim([None,1])\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.ylabel('Validation error rate',fontsize=20)\n",
    "# plt.savefig('paper_plots/error_rate_lr-4_2.pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# plot validation error rate on log-symlog plot\n",
    "plt.figure(figsize=(8,6))\n",
    "ax=plt.gca()\n",
    "plt.plot(m_ep_arr[:],err_rates[:],linewidth=5,alpha=0.8,label='Data')\n",
    "plt.plot(ep_arr[1:],np.exp(lin_fit_fun(np.log(ep_arr[1:]),*lin_popt)),'k',linestyle='dashed',label='Power-law fit')\n",
    "# plt.plot(ep_arr[1:],np.exp(lin_fit_fun(np.log(ep_arr[1:]),*lin_popt_2)),'r',linestyle='dashed',label='Late Power-law fit')\n",
    "plt.yscale('log')\n",
    "ax.set_xscale('symlog',linthresh=1)\n",
    "ll=ticker.SymmetricalLogLocator(linthresh=1,base=10)\n",
    "ll.set_params([2,3,4,5,6,7,8,9])\n",
    "ax.xaxis.set_minor_locator(ll)\n",
    "plt.xticks(list(plt.xticks()[0]) + [m_ep_arr[0]],list(plt.xticks()[1])+['$0$'])\n",
    "plt.legend(fontsize=15)\n",
    "# plt.ylim([None,1])\n",
    "plt.xlim([m_ep_arr[0]-0.1,600])\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.ylabel('Validation error rate',fontsize=20)\n",
    "# plt.savefig('paper_plots/error_rate_lr-4_2_log.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# The bond matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bond matrix using weights at a specific training time\n",
    "def bmat(tparams):\n",
    "    bl_rows=[]\n",
    "    for i in range(num_layers):\n",
    "        row=[]\n",
    "        for j in range(num_layers):\n",
    "            if j==i-1:\n",
    "                row.append(tparams[j])\n",
    "            else:\n",
    "                row.append(np.zeros((layers[i],layers[j])))\n",
    "        bl_rows.append(row)\n",
    "    bmat=np.block(bl_rows)\n",
    "    return bmat+bmat.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose two training times to compare. Generally start and end of training.\n",
    "ep_start=0\n",
    "ep_end=-1\n",
    "\n",
    "# create bond matrices at those times\n",
    "B_start=bmat(params[ep_start])\n",
    "B_end=bmat(params[ep_end])\n",
    "\n",
    "# find eigenvalues an eigenvectors\n",
    "eigs_start,evs_start=linalg.eigh(B_start)\n",
    "evs_start=evs_start.T\n",
    "eigs_end,evs_end=linalg.eigh(B_end)\n",
    "evs_end=evs_end.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to file\n",
    "out_dict={\n",
    "    \"ref_file\": filepath,\n",
    "    \"eigs_start\": list(eigs_start),\n",
    "    \"eigs_end\": list(eigs_end)\n",
    "}\n",
    "\n",
    "with open(\"train_data/Jevals_mnist_relu_paper_lr-4_2.json\",\"w\") as outfile:\n",
    "#     json.dump(out_dict,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to read in previously computed results\n",
    "with open(\"train_data/Jevals_mnist_paper_relu_lr-4.json\",\"r\") as file:\n",
    "    in_dict=json.load(file)\n",
    "\n",
    "eigs_start=np.array(in_dict[\"eigs_start\"])\n",
    "eigs_end=np.array(in_dict[\"eigs_end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bond matrix spectrum zoomed in to neglect central spike\n",
    "counts_end, bins,_=plt.hist(eigs_end,bins=100, density=True)\n",
    "plt.close()\n",
    "plt.figure(figsize=(8,6))\n",
    "counts_start,_,_=plt.hist(eigs_start,bins=bins, density=True,alpha=0.5,label=\"Before Training\")\n",
    "counts_end, bins,_=plt.hist(eigs_end,bins=bins, density=True,alpha=0.5,label=\"After Training\")\n",
    "plt.xlim([-7,7])\n",
    "plt.ylim([0,0.3])\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Eigenvalues of $J$',fontsize=20)\n",
    "plt.ylabel('Spectral Density',fontsize=20)\n",
    "# plt.savefig('paper_plots/spectrum_hist_relu_lr-4_zoom.pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# plot bond matrix spectrum\n",
    "counts_end, bins,_=plt.hist(eigs_end,bins=100, density=True)\n",
    "plt.close()\n",
    "plt.figure(figsize=(8,6))\n",
    "counts_start,_,_=plt.hist(eigs_start,bins=bins, density=True,alpha=0.5,label=\"Before Training\")\n",
    "counts_end, bins,_=plt.hist(eigs_end,bins=bins, density=True,alpha=0.5,label=\"After Training\")\n",
    "plt.xlim([-7,7])\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Eigenvalues of $J$',fontsize=20)\n",
    "plt.ylabel('Spectral Density',fontsize=20)\n",
    "# plt.savefig('paper_plots/spectrum_hist_relu_lr-4.pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# plot bond matrix spectrum on log plot\n",
    "counts_end, bins,_=plt.hist(eigs_end,bins=100, density=True)\n",
    "plt.close()\n",
    "plt.figure(figsize=(8,6))\n",
    "counts_start,_,_=plt.hist(eigs_start,bins=bins, density=True,alpha=0.5,label=\"Before Training\")\n",
    "counts_end, bins,_=plt.hist(eigs_end,bins=bins, density=True,alpha=0.5,label=\"After Training\")\n",
    "plt.xlim([-7,7])\n",
    "plt.yscale('log')\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Eigenvalues of $J$',fontsize=20)\n",
    "plt.ylabel('Spectral Density',fontsize=20)\n",
    "# plt.savefig('paper_plots/spectrum_hist_relu_lr-4_log.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## row-wise sum of squares of bond matrix elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute row-wise sums of squares at times defined above\n",
    "J2s_start=np.sum(B_start**2,axis=0)\n",
    "J2s_end=np.sum(B_end**2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to file\n",
    "out_dict={\n",
    "    \"ref_file\": filepath,\n",
    "    \"J2s_start\": list(J2s_start),\n",
    "    \"J2s_end\": list(J2s_end)\n",
    "}\n",
    "\n",
    "with open(\"train_data/J2s_mnist_paper_lr-4_2.json\",\"w\") as outfile:\n",
    "#     json.dump(out_dict,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create histogram and then discard to define the bins\n",
    "counts_end, bins,_=plt.hist(eigs_end,bins=100, density=True)\n",
    "plt.close()\n",
    "\n",
    "# plot histogram of sums\n",
    "counts_end, bins,_=plt.hist(eigs_end,bins=100, density=True)\n",
    "plt.close()\n",
    "plt.figure(figsize=(8,6))\n",
    "counts_start,_,_=plt.hist(J2s_start,bins=bins, density=True,alpha=0.5,label=\"Before Training\")\n",
    "counts_end, bins,_=plt.hist(J2s_end,bins=bins, density=True,alpha=0.5,label=\"After Training\")\n",
    "# plt.xlim([-7,7])\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('$J^2$',fontsize=20)\n",
    "plt.ylabel('Spectral Density',fontsize=20)\n",
    "# plt.savefig('paper_plots/spectrum_hist_lr-7.pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#plot histogram of sums on log plot\n",
    "counts_end, bins,_=plt.hist(eigs_end,bins=100, density=True)\n",
    "plt.close()\n",
    "plt.figure(figsize=(8,6))\n",
    "counts_start,_,_=plt.hist(J2s_start,bins=bins, density=True,alpha=0.5,label=\"Before Training\")\n",
    "counts_end, bins,_=plt.hist(J2s_end,bins=bins, density=True,alpha=0.5,label=\"After Training\")\n",
    "# plt.xlim([-7,7])\n",
    "plt.yscale('log')\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('$J^2$',fontsize=20)\n",
    "plt.ylabel('Spectral Density',fontsize=20)\n",
    "# plt.savefig('paper_plots/spectrum_hist_lr-7_log.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the minimum row-wise sum of squares at each time step\n",
    "mins=[]\n",
    "for param in tqdm(params):\n",
    "    J=bmat(param)\n",
    "    mins.append(min(np.sum(J**2,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to file\n",
    "out_dict={\n",
    "    \"ref_file\": filepath,\n",
    "    \"J2_mins\": list(mins)\n",
    "}\n",
    "\n",
    "with open(\"train_data/J2mins_mnist_paper_lr-4_2.json\",\"w\") as outfile:\n",
    "#     json.dump(out_dict,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to read in the results from a file\n",
    "with open(\"train_data/J2mins_mnist_relu_paper_lr-4.json\",\"r\") as file:\n",
    "    in_dict=json.load(file)\n",
    "\n",
    "mins=np.array(in_dict[\"J2_mins\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot minimum across training time to see how much it changes\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(ep_arr,mins)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the ratio of the change across training to original value\n",
    "(mins[-1]-mins[0])/mins[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Maximum eigenvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the maximum eigenvalue of bond matrix across training\n",
    "max_eigs=[]\n",
    "for param in tqdm(params):\n",
    "    J=bmat(param)\n",
    "    eig=max(linalg.eigvalsh(J))\n",
    "    max_eigs.append(eig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to file\n",
    "out_dict={\n",
    "    \"ref_file\": filepath,\n",
    "    \"max_eigs\": list(max_eigs)\n",
    "}\n",
    "\n",
    "with open(\"train_data/maxs_mnist_paper_lr-4_2.json\",\"w\") as outfile:\n",
    "#     json.dump(out_dict,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to read in the results from a file\n",
    "with open(\"train_data/maxs_mnist_paper_lr-4_2.json\",\"r\") as file:\n",
    "    in_dict=json.load(file)\n",
    "\n",
    "max_eigs=np.array(in_dict[\"max_eigs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit log-log max eigenvalue data in different regimes\n",
    "lin_popt,_=opt.curve_fit(lin_fit_fun,np.log(ep_arr[10:80]),np.log(max_eigs[10:80]))\n",
    "print(lin_popt)\n",
    "\n",
    "lin_popt_2,_=opt.curve_fit(lin_fit_fun,np.log(ep_arr[300:]),np.log(max_eigs[300:]))\n",
    "print(lin_popt_2)\n",
    "\n",
    "# plot maximum eigenvalue across training\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(ep_arr, max_eigs,linewidth=5,alpha=0.8,label='Data')\n",
    "plt.plot(ep_arr,np.exp(lin_fit_fun(np.log(ep_arr),*lin_popt)),'k',linestyle='dashed',label='Power-law fit')\n",
    "plt.plot(ep_arr,np.exp(lin_fit_fun(np.log(ep_arr),*lin_popt_2)),'r',linestyle='dashed',label='Late Power-law fit')\n",
    "plt.ylim([2.4,None])\n",
    "# plt.xlim([0,20])\n",
    "plt.legend(fontsize=15)\n",
    "plt.ylabel('$\\\\lambda_{\\\\max}(J)$',fontsize=20)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "# plt.savefig('paper_plots/max_eig_lr-4_2.pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# plot maximum eigenvalue across training on log-symlog plot\n",
    "plt.figure(figsize=(8,6))\n",
    "ax=plt.gca()\n",
    "plt.plot(m_ep_arr[:], max_eigs[:],linewidth=5,alpha=0.8,label='Data')\n",
    "plt.plot(ep_arr[1:],np.exp(lin_fit_fun(np.log(ep_arr[1:]),*lin_popt)),'k',linestyle='dashed',label='Power-law fit')\n",
    "plt.plot(ep_arr[1:],np.exp(lin_fit_fun(np.log(ep_arr[1:]),*lin_popt_2)),'r',linestyle='dashed',label='Late Power-law fit')\n",
    "plt.ylim([2.5,None])\n",
    "plt.yscale('log')\n",
    "ax.set_xscale('symlog',linthresh=1)\n",
    "ll=ticker.SymmetricalLogLocator(linthresh=1,base=10)\n",
    "ll.set_params([2,3,4,5,6,7,8,9])\n",
    "ax.xaxis.set_minor_locator(ll)\n",
    "plt.xticks(list(plt.xticks()[0]) + [m_ep_arr[0]],list(plt.xticks()[1])+['$0$'])\n",
    "plt.xlim([m_ep_arr[0]-0.1,600])\n",
    "plt.legend(fontsize=15)\n",
    "plt.ylabel('$\\\\lambda_{\\\\max}(J)$',fontsize=20)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "# plt.savefig('paper_plots/max_eig_lr-4_2_log.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Eigenvalues of M (defined in TAP equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to find eigenvalues of the matrix defined by the linearized TAP equations given an inverse temp and bond matrix\n",
    "def eigsVbeta(betas,bmat):\n",
    "    eig_list=[]\n",
    "    for beta in tqdm(betas):\n",
    "        Mat=copy.deepcopy(bmat)\n",
    "        for i in range(len(bmat)):\n",
    "            Mat[i,i]=-beta*np.sum(Mat[i,:]**2)\n",
    "        Mat=beta*Mat\n",
    "\n",
    "        eig_list.append(linalg.eigh(Mat,eigvals_only=True))\n",
    "\n",
    "    return np.array(eig_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set two training times to compare. Usually start and end of training\n",
    "ep_start=0\n",
    "ep_end=-1\n",
    "\n",
    "# create bond matrices at those times\n",
    "B_start=bmat(params[ep_start])\n",
    "B_end=bmat(params[ep_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define array of betas to use for the calculation\n",
    "betas=np.linspace(0,1.2,20)\n",
    "\n",
    "# find eigenvalues\n",
    "eig_list_start=eigsVbeta(betas,B_start)\n",
    "eig_list_end=eigsVbeta(betas,B_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to file\n",
    "out_dict={\n",
    "    \"ref_file\": filepath,\n",
    "    \"eig_list_start\": [list(eig_list) for eig_list in eig_list_start],\n",
    "    \"eig_list_end\": [list(eig_list) for eig_list in eig_list_end],\n",
    "    \"betas\": list(betas)\n",
    "}\n",
    "\n",
    "with open(\"train_data/eig_min_ba_mnist_paper_lr-4_2.json\",\"w\") as outfile:\n",
    "#     json.dump(out_dict,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to read in results from a file\n",
    "with open(\"train_data/eig_min_ba_mnist_paper_lr-4_2.json\",\"r\") as file:\n",
    "    in_dict=json.load(file)\n",
    "\n",
    "eig_list_start=np.array(in_dict[\"eig_list_start\"])\n",
    "eig_list_end=np.array(in_dict[\"eig_list_end\"])\n",
    "betas=np.array(in_dict[\"betas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot eigs v beta at first time\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(betas,eig_list_start)\n",
    "plt.axhline(1)\n",
    "plt.ylim([-1,2])\n",
    "plt.xlabel('$\\\\beta$')\n",
    "plt.ylabel('eigenvalues')\n",
    "#plt.text(4,-0.5,f'epoch {ep_num*5}')\n",
    "plt.show()\n",
    "\n",
    "# plot eigs v beta at second time\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(betas,eig_list_end)\n",
    "plt.axhline(1)\n",
    "plt.ylim([-1,2])\n",
    "plt.xlabel('$\\\\beta$')\n",
    "plt.ylabel('eigenvalues')\n",
    "#plt.text(4,-0.5,f'epoch {ep_num*5}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot minimum eig of 1-M before and after training\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(betas,1-eig_list_start[:,-1],label='Before training')\n",
    "plt.plot(betas,1-eig_list_end[:,-1],label='After training')\n",
    "plt.axhline(0,linestyle='dashed',c='gray')\n",
    "plt.axvline(0.8,linestyle='dotted',c='gray')\n",
    "plt.axvline(beta_ts[-1],linestyle='dotted',c='gray')\n",
    "plt.ylabel('$\\\\lambda_{\\\\min}(I_N-M)$',size=20)\n",
    "plt.xlabel('$\\\\beta$',size=20)\n",
    "plt.legend(fontsize=15)\n",
    "# plt.ylim([-0.1,0.1])\n",
    "# plt.savefig('paper_plots/min_eig_evo_lr-4_2.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Transition temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define quadratic function for fitting\n",
    "def quad_fit_fun(x,a,b,c):\n",
    "    return -a*(x-b)**2+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ending index (generally the end of training), array of betas, and initialize the crossover value to 1.\n",
    "end_idx=len(params)\n",
    "betas=np.linspace(0.1,0.9,20)\n",
    "cross_val=1\n",
    "beta_ts=[]\n",
    "\n",
    "# start with weights before training\n",
    "tparams=params[0]\n",
    "l_evals=[]\n",
    "# calculate M at each beta\n",
    "for beta in betas:\n",
    "    Mat=bmat(tparams)\n",
    "    for i in range(N):\n",
    "        Mat[i,i]=-beta*np.sum(Mat[i,:]**2)\n",
    "    Mat=beta*Mat\n",
    "    # find largest eigenvector\n",
    "    l_evals.append(linalg.eigh(Mat,eigvals_only=True,subset_by_index=[N-1,N-1])[0])\n",
    "\n",
    "# find at which beta the largest eigenvalue first becomes greater than one\n",
    "# if this does not happen, take the beta which maximizes the curve\n",
    "cross_idx=None\n",
    "for i in range(len(betas)):\n",
    "    if l_evals[i]>=1:\n",
    "        cross_idx=i\n",
    "        break\n",
    "if cross_idx==None:\n",
    "    cross_idx=np.argmax(l_evals)\n",
    "# find a quadratic fit around the selected beta\n",
    "qpopt,_=opt.curve_fit(quad_fit_fun,betas[cross_idx-2:cross_idx+2],l_evals[cross_idx-2:cross_idx+2])\n",
    "a,b,c=qpopt\n",
    "# set the crossover value to the maximum of this quadratic fit\n",
    "cross_val=c\n",
    "print(cross_val)\n",
    "# store the value of beta corresponding to the maximum as the transition temperature\n",
    "beta_ts.append(b)\n",
    "\n",
    "# carry through the transition temp calulation for the other times using the new crossover value\n",
    "for k in tqdm(range(1,end_idx)):\n",
    "    tparams=params[k]\n",
    "    l_evals=[]\n",
    "    for beta in betas:\n",
    "        Mat=bmat(tparams)\n",
    "        for i in range(N):\n",
    "            Mat[i,i]=-beta*np.sum(Mat[i,:]**2)\n",
    "        Mat=beta*Mat\n",
    "        \n",
    "        l_evals.append(linalg.eigh(Mat,eigvals_only=True,subset_by_index=[N-1,N-1])[0])\n",
    "    \n",
    "    cross_idx=None\n",
    "    for i in range(len(betas)):\n",
    "        if l_evals[i]>=1:\n",
    "            cross_idx=i\n",
    "            break\n",
    "    if cross_idx==None:\n",
    "        cross_idx=np.argmax(l_evals)\n",
    "    qpopt,_=opt.curve_fit(quad_fit_fun,betas[cross_idx-2:cross_idx+2],l_evals[cross_idx-2:cross_idx+2])\n",
    "    a,b,c=qpopt\n",
    "    if c>=cross_val:\n",
    "        beta_ts.append(b-np.sqrt((c-cross_val)/a))\n",
    "    else:\n",
    "        beta_ts.append(b-1j*np.sqrt((cross_val-c)/a))   \n",
    "    \n",
    "beta_ts=np.array(beta_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the results to a file\n",
    "out_dict={\n",
    "    \"ref_file\": filepath,\n",
    "    \"beta_ts_real\": list(np.real(beta_ts)),\n",
    "    \"beta_ts_imag\": list(np.imag(beta_ts))\n",
    "}\n",
    "\n",
    "with open(\"train_data/betas_mnist_relu_paper_lr-4_adj.json\",\"w\") as outfile:\n",
    "#     json.dump(out_dict,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to read in the results from a file\n",
    "with open(\"train_data/betas_mnist_paper_lr-6_adj.json\",\"r\") as file:\n",
    "    in_dict=json.load(file)\n",
    "\n",
    "beta_ts=np.array(in_dict[\"beta_ts_real\"])+1j*np.array(in_dict[\"beta_ts_imag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit log-log transition temp data to line in different regimes\n",
    "popt,_=opt.curve_fit(lin_fit_fun,np.log(ep_arr[10:80]),np.log(np.array(1/beta_ts[10:80])))\n",
    "print(popt)\n",
    "\n",
    "popt_2,_=opt.curve_fit(lin_fit_fun,np.log(ep_arr[300:]),np.log(np.array(1/beta_ts[300:])))\n",
    "print(popt)\n",
    "\n",
    "# plot transition temperature\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(ep_arr, 1/beta_ts,linewidth=5,alpha=0.8,label='Data')\n",
    "plt.plot(ep_arr[0:],np.exp(lin_fit_fun(np.log(ep_arr[0:]),*popt)),'k',linestyle='dashed',label='Power-law fit')\n",
    "plt.plot(ep_arr[0:],np.exp(lin_fit_fun(np.log(ep_arr[0:]),*popt_2)),'r',linestyle='dashed',label='Late Power-law fit')\n",
    "plt.ylim([1/0.9,None])\n",
    "plt.ylabel(\"$T_c$\",fontsize=20)\n",
    "plt.xlabel(\"Epoch\",fontsize=20)\n",
    "plt.legend(fontsize=15)\n",
    "# plt.xlim([None,120])\n",
    "# plt.xlim([0,20])\n",
    "# plt.savefig('paper_plots/ttemp_lr-4_2.pdf',bbox_inches = \"tight\")\n",
    "plt.show()\n",
    "\n",
    "# plot transition temperataure on log-symlog plot\n",
    "plt.figure(figsize=(8,6))\n",
    "ax=plt.gca()\n",
    "plt.plot(m_ep_arr[:], 1/beta_ts[:],linewidth=5,alpha=0.8,label='Data')\n",
    "plt.plot(ep_arr[1:],np.exp(lin_fit_fun(np.log(ep_arr[1:]),*popt)),'k',linestyle='dashed',label='Power-law fit')\n",
    "plt.plot(ep_arr[1:],np.exp(lin_fit_fun(np.log(ep_arr[1:]),*popt_2)),'r',linestyle='dashed',label='Late Power-law fit')\n",
    "plt.ylabel(\"$T_c$\",fontsize=20)\n",
    "plt.xlabel(\"Epoch\",fontsize=20)\n",
    "plt.yscale('log')\n",
    "ax.set_xscale('symlog',linthresh=1)\n",
    "ll=ticker.SymmetricalLogLocator(linthresh=1,base=10)\n",
    "ll.set_params([2,3,4,5,6,7,8,9])\n",
    "ax.xaxis.set_minor_locator(ll)\n",
    "plt.xticks(list(plt.xticks()[0]) + [m_ep_arr[0]],list(plt.xticks()[1])+['$0$'])\n",
    "plt.xlim([m_ep_arr[0]-0.1,600])\n",
    "plt.ylim([1/0.9,None])\n",
    "plt.legend(fontsize=15)\n",
    "# plt.savefig('paper_plots/ttemp_lr-4_2_log.pdf',bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Eigenvalues of M at transition temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate eigenvalues of M at the transition temperature before and after training\n",
    "beta_t_start=beta_ts[0]\n",
    "beta_t_end=beta_ts[-1]\n",
    "\n",
    "param_start=params[0]\n",
    "param_end=params[-1]\n",
    "\n",
    "Mat_start=bmat(param_start).astype(complex)\n",
    "for i in range(N):\n",
    "    Mat_start[i,i]=-beta_t_start*np.sum(Mat_start[i,:]**2)\n",
    "Mat_start=beta_t_start*Mat_start\n",
    "Mevals_start=linalg.eigh(Mat_start,eigvals_only=True)\n",
    "\n",
    "Mat_end=bmat(param_end).astype(complex)\n",
    "for i in range(N):\n",
    "    Mat_end[i,i]=-beta_t_end*np.sum(Mat_end[i,:]**2)\n",
    "Mat_end=beta_t_end*Mat_end\n",
    "Mevals_end=linalg.eigh(Mat_end,eigvals_only=True)\n",
    "\n",
    "print(max(Mevals_start))\n",
    "print(max(Mevals_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to a file\n",
    "out_dict={\n",
    "    \"ref_file\": filepath,\n",
    "    \"Mevals_start\": list(Mevals_start),\n",
    "    \"Mevals_end\": list(Mevals_end)\n",
    "}\n",
    "\n",
    "with open(\"train_data/tevals_mnist_paper_lr-4_2.json\",\"w\") as outfile:\n",
    "#     json.dump(out_dict,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_num=100\n",
    "\n",
    "# plot eigenvalues of 1-M zoomed in to ignore sharp peaks\n",
    "plt.figure(figsize=(8,6))\n",
    "counts_start,bins,_=plt.hist(1-Mevals_start,bins=bin_num,alpha=0.5,density=True,label=\"Before Training\")\n",
    "counts_end,_,_=plt.hist(1-Mevals_end,bins=bins,alpha=0.5,density=True,label=\"After Training\")\n",
    "plt.ylim((0,1.5))\n",
    "# plt.xlim((0,1.1))\n",
    "plt.xlabel('Eigenvalues of $I_N-M$ at Transition Temperature',fontsize=20)\n",
    "plt.ylabel('Spectral Density',fontsize=20)\n",
    "plt.legend(fontsize=15)\n",
    "# plt.savefig('paper_plots/I-M_before_after_lr-4_2_zoom.pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# plot eigenvalues of 1-M\n",
    "plt.figure(figsize=(8,6))\n",
    "counts_start,bins,_=plt.hist(1-Mevals_start,bins=bin_num,alpha=0.5,density=True,label=\"Before Training\")\n",
    "counts_end,_,_=plt.hist(1-Mevals_end,bins=bins,alpha=0.5,density=True,label=\"After Training\")\n",
    "plt.xlabel('Eigenvalues of $I_N-M$ at Transition Temperature',fontsize=20)\n",
    "plt.ylabel('Spectral Density',fontsize=20)\n",
    "plt.legend(fontsize=15)\n",
    "# plt.savefig('paper_plots/I-M_before_after_lr-4_2.pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# plot eigenvalues of 1-M on log plot\n",
    "plt.figure(figsize=(8,6))\n",
    "counts_start,bins,_=plt.hist(1-Mevals_start,bins=bin_num,alpha=0.5,density=True,label=\"Before Training\")\n",
    "counts_end,_,_=plt.hist(1-Mevals_end,bins=bins,alpha=0.5,density=True,label=\"After Training\")\n",
    "plt.xlabel('Eigenvalues of $I_N-M$ at Transition Temperature',fontsize=20)\n",
    "plt.ylabel('Spectral Density',fontsize=20)\n",
    "plt.yscale('log')\n",
    "plt.legend(fontsize=15)\n",
    "# plt.savefig('paper_plots/I-M_before_after_lr-4_2_log.pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(counts_start[0])\n",
    "print(counts_end[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Evolution of first level spacing of 1-M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the first level spacing and normalized first level spacing across training\n",
    "gaps=[]\n",
    "norm_gaps=[]\n",
    "\n",
    "for j in tqdm(range(len(beta_ts))):\n",
    "    tparams=params[j]\n",
    "    beta=beta_ts[j]\n",
    "    Mat=bmat(tparams).astype(complex)\n",
    "    for i in range(N):\n",
    "        Mat[i,i]=-beta*np.sum(Mat[i,:]**2)\n",
    "    Mat=beta*Mat\n",
    "    evals=linalg.eigh(Mat,eigvals_only=True)\n",
    "    spacings=[evals[i+1]-evals[i] for i in range(len(evals)-1)]\n",
    "    gaps.append(spacings[-1])\n",
    "    norm_gaps.append(spacings[-1]/np.median(spacings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to a file\n",
    "out_dict={\n",
    "    \"ref_file\": filepath,\n",
    "    \"gaps\": gaps,\n",
    "    \"norm_gaps\": norm_gaps\n",
    "}\n",
    "\n",
    "with open(\"train_data/gaps_mnist_paper_lr-4.json\",\"w\") as outfile:\n",
    "#     json.dump(out_dict,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to read in the results from a file\n",
    "with open(\"train_data/gaps_mnist_paper_lr-4_2.json\",\"r\") as file:\n",
    "    in_dict=json.load(file)\n",
    "\n",
    "gaps=in_dict['gaps']\n",
    "norm_gaps=in_dict['norm_gaps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit log-log first spacing data to linear function\n",
    "popt,_=opt.curve_fit(lin_fit_fun,np.log(ep_arr[10:40]),np.log(np.array(gaps[10:40])))\n",
    "print(popt)\n",
    "\n",
    "# plot first level spacing\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(ep_arr,gaps,alpha=0.8,label=\"Data\")\n",
    "# plt.plot(ep_arr[1:],np.exp(lin_fit_fun(np.log(ep_arr[1:]),*popt)),'k',linestyle='dashed',label='Power-law fit')\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.ylabel('$s_{0}$',fontsize=20)\n",
    "# plt.savefig('paper_plots/gaps_lr-4_2.pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# plot first level spacing on log-log plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(ep_arr[1:],gaps[1:],alpha=0.8,label=\"Data\")\n",
    "# plt.plot(ep_arr[1:],np.exp(lin_fit_fun(np.log(ep_arr[1:]),*popt)),'k',linestyle='dashed',label='Power-law fit')\n",
    "plt.axhline(gaps[0],linestyle='dotted',color='gray')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "# plt.ylim([.025,None])\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.ylabel('$s_{0}$',fontsize=20)\n",
    "# plt.savefig('paper_plots/gaps_lr-4_2_log.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit log-log normalized first level spacing to linear function\n",
    "popt,_=opt.curve_fit(lin_fit_fun,np.log(ep_arr[250:]),np.log(np.array(norm_gaps[250:])))\n",
    "print(popt)\n",
    "\n",
    "# plot normalized first level spacing\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(ep_arr,norm_gaps,linewidth=3,alpha=0.8,label=\"Data\")\n",
    "# plt.plot(ep_arr,np.exp(lin_fit_fun(np.log(ep_arr),*popt)),'k',linestyle='dashed',label='Power-law fit')\n",
    "# plt.ylim([None,120])\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.ylabel('$s_0/s_{\\\\mathrm{typ}}$',fontsize=20)\n",
    "# plt.savefig('paper_plots/norm_gaps_lr-4_2.pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# plot normalized first level spacing on log-symlog plot\n",
    "plt.figure(figsize=(8,6))\n",
    "ax=plt.gca()\n",
    "plt.plot(m_ep_arr[:],norm_gaps[:],linewidth=3,alpha=0.8,label=\"Data\")\n",
    "# plt.plot(ep_arr[1:],np.exp(lin_fit_fun(np.log(ep_arr[1:]),*popt)),'k',linestyle='dashed',label='Power-law fit')\n",
    "plt.yscale('log')\n",
    "ax.set_xscale('symlog',linthresh=1)\n",
    "ll=ticker.SymmetricalLogLocator(linthresh=1,base=10)\n",
    "ll.set_params([2,3,4,5,6,7,8,9])\n",
    "ax.xaxis.set_minor_locator(ll)\n",
    "plt.xticks(list(plt.xticks()[0]) + [m_ep_arr[0]],list(plt.xticks()[1])+['$0$'])\n",
    "plt.xlim([m_ep_arr[0]-0.1,600])\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.ylabel('$s_0/s_{\\\\mathrm{typ}}$',fontsize=20)\n",
    "# plt.savefig('paper_plots/norm_gaps_lr-4_2_log.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
